# MachineLearning-Learn

**1. Machine Learning Course - Kaggle**

- **Data Exploration**: Utilizing pandas to explore and manipulate the Melbourne home prices dataset.

- **First Machine Learning Model**: Selecting features, defining, fitting, predicting, and evaluating a Decision Tree model.

- **Model Validation**: Splitting data into training and validation sets to measure model accuracy using Mean Absolute Error (MAE).

- **Underfitting and Overfitting**: Addressing model performance issues by adjusting the complexity of the Decision Tree model.

- **Random Forest**: Introducing the Random Forest model as a means to improve predictions by averaging multiple decision trees.

**2. Intermediate Machine Learning Course - Kaggle**

- **Introduction to ML**: The notebook begins with an introduction to machine learning, importing necessary libraries, and preparing the dataset for house price prediction.

- **Model Evaluation**: It defines five random forest models with different parameters and uses a function to calculate the mean absolute error (MAE) to evaluate their performance.

- **Missing Values**: The notebook discusses three approaches to handle missing values: dropping columns with missing values, imputation, and an extension to imputation.

- **Categorical Variables**: It explores handling categorical variables using techniques like dropping categorical variables, ordinal encoding, and one-hot encoding.

- **Pipelines**: The notebook introduces pipelines to streamline preprocessing and modeling steps.

- **Cross-Validation**: It explains the concept of cross-validation and demonstrates how to implement it.

- **XGBoost**: The notebook covers the XGBoost model, parameter tuning, and how to prevent overfitting with early stopping.

- **Data Leakage**: It concludes with a discussion on data leakage and how to avoid it.

**3. Feature Engineering - Kaggle**

- **Mutual Information (MI)**: Using MI to rank features based on their association with the target, capturing any kind of relationship beyond just linear.

- **Creating Features**: Generating new features through mathematical transformations, counts, and group transforms to capture more information.

- **Clustering with K-Means**: Utilizing K-Means clustering to create features that capture complex spatial relationships.

- **Principal Component Analysis (PCA)**: Implementing PCA to reduce dimensionality and discover important relationships in the data.
  
- **Target Encoding**: Applying target encoding to categorical features to capture information related to the target variable.
